# Code Generated by Sidekick is for learning and experimentation purposes only.
from langchain_community.chat_models import ChatOpenAI
from langchain.memory import ConversationBufferMemory
from langchain.chains import ConversationChain
from langchain_core.prompts import ChatPromptTemplate
from langchain_community.document_loaders import TextLoader
import dotenv
from elevenlabs import stream
from elevenlabs.client import ElevenLabs
import sounddevice as sd
import numpy as np
import wave
from io import BytesIO
import os
import argparse

dotenv.load_dotenv()

# Load environment variables
temperature = float(os.getenv("TEMPERATURE", 0.7))
llm_model = os.getenv("LLM_MODEL", "gpt-3.5-turbo")
base_url = os.getenv("BASE_URL", "https://api.openai.com/v1")
api_key = os.getenv("API_KEY")
elevenlabs_api_key = os.getenv("ELEVENLABS_API_KEY")

parser = argparse.ArgumentParser()
parser.add_argument("--list_voices", action="store_true", help="List the available voices for the text-to-speech engine")
parser.add_argument("--duration", type=int, default=5, help="Recording duration in seconds (default: 5)")
parser.add_argument("--voice", type=str, default="EXAVITQu4vr4xnSDxMaL", help="Voice ID to use (default: Rachel)")
args = parser.parse_args()

# Define the interview prompt
INTERVIEW_PROMPT = """#Role: you are Daria, a UX researcher conducting an application review interview
#Objective: You are conducting an interview about your experience with using the Whirlpool Self-Service Ordering Portal
#Instructions: Ask questions to understand the interviewee's role, experience, and needs related to the portal. NEVER REPEAT A QUESTION! If the human's answer warrants a follow-up question, ask the follow-up question. Do not ask more than 1 follow-up question. Never repeat a follow-up question.
If the human has answered the follow-up question, move onto the next question. If the human answers with a gibberish or irrelevant response, do not say great answer or any give any other form of encouragement.
Make sure to assess their response before asking a follow-up question. If their answer is self-contained and comprehensive it's not necessary to ask a follow-up question."""

# Define available voices
AVAILABLE_VOICES = {
    "rachel": "EXAVITQu4vr4xnSDxMaL",  # Rachel - Professional Female
    "antoni": "ErXwobaYiN019PkySvjV",  # Antoni - Female
    "elli": "MF3mGyEYCl7XYWbV9V6O",   # Elli - Female
    "domi": "AZnzlk1XvdvUeBnXmlld",    # Domi - Female
    "josh": "TxGEqnHWrfWFTfGW9XjX",    # Josh - Male
    "arnold": "VR6AewLTigWG4xSOukaG",   # Arnold - Male
    "adam": "pNInz6obpgDQGcFmaJgB",     # Adam - Male
}

llm = ChatOpenAI(temperature=temperature, model=llm_model, base_url=base_url, api_key=api_key)
elevenlabs_client = ElevenLabs(api_key=elevenlabs_api_key)

def record_audio(duration=5, sample_rate=16000):
    """Record audio from microphone"""
    print(f"Recording for {duration} seconds...")
    recording = sd.rec(int(duration * sample_rate), samplerate=sample_rate, channels=1)
    sd.wait()
    print("Recording finished")
    return recording

def save_audio(recording, filename="temp_recording.wav", sample_rate=16000):
    """Save recorded audio to WAV file"""
    with wave.open(filename, 'wb') as wf:
        wf.setnchannels(1)
        wf.setsampwidth(2)
        wf.setframerate(sample_rate)
        wf.writeframes((recording * 32767).astype(np.int16).tobytes())
    return filename

# Function to convert text to speech using ElevenLabs
def speak(text):
    try:
        voice_id = AVAILABLE_VOICES.get(args.voice.lower(), args.voice)
        audio_stream = elevenlabs_client.text_to_speech.convert_as_stream(
            text=text,
            voice_id=voice_id,
            model_id="eleven_multilingual_v2"
        )
        stream(audio_stream)
    except Exception as e:
        if "quota_exceeded" in str(e):
            print("\n[Note: ElevenLabs quota exceeded. Text will be displayed only.]")
        else:
            print(f"\n[Error with text-to-speech: {str(e)}]")
        print(f"Text: {text}")

# Function to recognize speech and convert it to text using ElevenLabs
def listen():
    try:
        # Record audio
        recording = record_audio(duration=args.duration)
        
        # Save audio to temporary file
        audio_file = save_audio(recording)
        
        # Transcribe audio using ElevenLabs
        with open(audio_file, 'rb') as f:
            audio_data = BytesIO(f.read())
            transcription = elevenlabs_client.speech_to_text.convert(
                file=audio_data,
                model_id="scribe_v1",
                tag_audio_events=True,
                language_code="eng",
                diarize=True,
            )
        
        # Clean up temporary file
        if os.path.exists(audio_file):
            os.remove(audio_file)
            
        text = transcription.text
        print(f"User said: {text}")
        return text
        
    except Exception as e:
        print(f"Error during speech recognition: {e}")
        return ""

if __name__ == '__main__':
    if args.list_voices:
        print("\nAvailable Voices:")
        print("-" * 50)
        for name, voice_id in AVAILABLE_VOICES.items():
            print(f"Name: {name.capitalize()}")
            print(f"ID: {voice_id}")
            print("-" * 50)
        print("\nTo use a voice, run with --voice <name>")
        print("Example: python3 tests/daria.py --voice rachel")
    else:
        voice_name = next((name for name, id in AVAILABLE_VOICES.items() if id == args.voice), args.voice)
        print(f"\nRecording duration set to {args.duration} seconds")
        print("Note: Each second of audio typically uses about 1-2 tokens for speech-to-text conversion")
        print(f"Estimated tokens per recording: {args.duration * 2} tokens")
        print("Current ElevenLabs pricing: $0.0001 per token")
        print(f"\nUsing {voice_name.capitalize()} voice for Daria\n")
        
        # using gpt 4o mini which does quite well to ask good questions
        llm = ChatOpenAI(model="gpt-4o-mini", temperature=1)
        memory = ConversationBufferMemory()
        conversation = ConversationChain(llm=llm, memory=memory)
        
        # save the interview transcript to a file for langchain doc loader to load as context
        f = open("transcript.txt", "w")
        f.write("Interviewer: Daria (UX Researcher)\n")
        speak("Hello, I'm Daria, a UX researcher. How are you? Say Start to begin the contextual inquiry interview about the Whirlpool Self-Service Ordering Portal!")
        print("Hello, I'm Daria, a UX researcher. How are you? Type Start to begin the contextual inquiry interview about the Whirlpool Self-Service Ordering Portal!")
        i = 0

        # check whether the user is interested in being interviewed
        user_input = listen()

        # Press Start to go!
        if user_input.lower() == 'start':
            # Get the first question from the model
            question = conversation.predict(input=INTERVIEW_PROMPT)

            # get the user's answer from the console
            speak(f"Daria: {question}")
            user_input = listen()
            print("Your answer: " + user_input)
            f.write("Daria: " + question + "\n")
            f.write("Interviewee: " + user_input + "\n")

        for i in range(0, 4):
            prompt = "Continue the interview about the Whirlpool Self-Service Ordering Portal and ask the next question or follow-up question."
            question = conversation.predict(input=prompt)
            # if a follow-up question was asked don't go to the next question yet
            if 'follow' in question.lower():
                i = i - 1
            speak(f"Daria: {question}")
            user_input = listen()
            print("Your answer: " + user_input)
            f.write("Daria: " + question + "\n")
            f.write("Interviewee: " + user_input + "\n")

        f.close()
        # load the interview transcript
        loader = TextLoader("./transcript.txt")
        documents = loader.load()
        context = " ".join([doc.page_content for doc in documents])

        # construct the prompt template to invoke ChatOpenAI
        question = "What is your assessment of the interviewee's responses about the Whirlpool Self-Service Ordering Portal?"
        evaluator_prompt = "You are Daria, an expert UX researcher conducting contextual inquiry interviews. You evaluate interview transcripts and generate a report on the interviewee's responses. The report should include insights into their role, experience, needs, and any key frustrations or suggestions they have mentioned about the Whirlpool Self-Service Ordering Portal. Be critical in your evaluation and provide a comprehensive summary of the interviewee's input."

        context = evaluator_prompt + context
        prompt_template = ChatPromptTemplate.from_template(
            "Here is the context:\n{context}\nAnswer the following question:\n{question}"
        )
        
        # Use the LLM directly instead of LLMChain
        response = llm.invoke(prompt_template.format(context=context, question=question))
        
        # print the final evaluation report
        print(f"\nDaria's Assessment: {response.content}")
        speak(f"Daria's Assessment: {response.content}")